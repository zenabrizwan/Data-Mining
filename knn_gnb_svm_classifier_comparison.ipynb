{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sm_MP3adbkJY"
      },
      "outputs": [],
      "source": [
        "class NearestNeighborClassifierManual:\n",
        "    def __init__(self):\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        #To Do\n",
        "        for test_instance in X_test:\n",
        "      # Calculate distances to all training points\n",
        "          distances = np.linalg.norm(self.X_train - test_instance, axis=1)\n",
        "\n",
        "      # Find k nearest neighbors\n",
        "          k_nearest_indices = np.argsort(distances)[:k]\n",
        "\n",
        "      # Get nearest neighbor labels\n",
        "          nearest_neighbor_labels = self.y_train[k_nearest_indices]\n",
        "\n",
        "      # Majority vote for prediction\n",
        "          prediction = np.argmax(np.bincount(nearest_neighbor_labels))\n",
        "\n",
        "          predictions.append(prediction)\n",
        "    return np.array(predictions)\n",
        "\n",
        "\n",
        "# Import GaussianNaiveBayesClassifierManual\n",
        "class GaussianNaiveBayesClassifierManual:\n",
        "    def __init__(self):\n",
        "        self.class_priors = None\n",
        "        self.class_means = None\n",
        "        self.class_variances = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        self.class_priors = {}\n",
        "        self.class_means = {}\n",
        "        self.class_variances = {}\n",
        "        classes = np.unique(y_train)\n",
        "        for c in classes:\n",
        "      # Get data points belonging to class c\n",
        "          X_c = X_train[y_train == c]\n",
        "\n",
        "      # Calculate class prior\n",
        "          self.class_priors[c] = len(X_c) / len(y_train)\n",
        "\n",
        "      # Calculate class mean\n",
        "          self.class_means[c] = np.mean(X_c, axis=0)\n",
        "\n",
        "      # Calculate class variance (add epsilon for smoothing)\n",
        "          self.class_variances[c] = np.var(X_c, axis=0) + 1e-10\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        predictions = []\n",
        "        #To Do\n",
        "        for x in X_test:\n",
        "          posteriors = {}\n",
        "          for c in self.class_priors:\n",
        "        # Calculate probability density for each feature\n",
        "            pdfs = np.exp(-0.5 * np.sum(((x - self.class_means[c])**2) / (self.class_variances[c] + 1e-10), axis=0))\n",
        "\n",
        "        # Class prior * product of feature probabilities\n",
        "            posteriors[c] = self.class_priors[c] * np.prod(pdfs)\n",
        "\n",
        "      # Predict class with highest posterior probability\n",
        "          prediction = max(posteriors, key=posteriors.get)\n",
        "          predictions.append(prediction)\n",
        "        return np.array(predictions)\n",
        "\n",
        "\n",
        "class SupportVectorMachineClassifierManual:\n",
        "    def __init__(self, learning_rate=0.001, epochs=1000):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def fit(self, X_train, y_train):\n",
        "        n_samples, n_features = X_train.shape\n",
        "        self.weights = np.zeros(n_features)\n",
        "        self.bias = 0\n",
        "        #To Do\n",
        "            # Loop for training epochs\n",
        "        for _ in range(self.epochs):\n",
        "          for i in range(n_samples):\n",
        "        # Get current sample and label\n",
        "            x_i = X_train[i]\n",
        "            y_i = y_train[i]\n",
        "\n",
        "        # Predicted value\n",
        "            predicted = np.dot(self.weights, x_i) + self.bias\n",
        "\n",
        "        # Update weights only if prediction violates margin\n",
        "            if (y_i == 1 and predicted < 1) or (y_i == -1 and predicted > -1):\n",
        "          # Update rule with hinge loss\n",
        "              update = self.learning_rate * (y_i - predicted) * x_i\n",
        "              self.weights += update\n",
        "              self.bias += self.learning_rate * (y_i - predicted)\n",
        "\n",
        "\n",
        "    def predict(self, X_test):\n",
        "        #To Do\n",
        "          predictions = []\n",
        "    for x in X_test:\n",
        "      predicted = np.dot(self.weights, x) + self.bias\n",
        "      # Apply sign function for binary classification\n",
        "      prediction = np.sign(predicted)\n",
        "      predictions.append(prediction)\n",
        "    return np.array(predictions)\n",
        "\n",
        "\n",
        "class ConfusionMatrix:\n",
        "    def __init__(self, y_true, y_pred):\n",
        "        self.y_true = y_true\n",
        "        self.y_pred = y_pred\n",
        "        self.n_classes = len(np.unique(y_true))\n",
        "        self.matrix = self._compute_confusion_matrix()\n",
        "\n",
        "    def _compute_confusion_matrix(self):\n",
        "        matrix = np.zeros((self.n_classes, self.n_classes), dtype=int)\n",
        "\n",
        "       for y_t, y_p in zip(self.y_true, self.y_pred):\n",
        "         matrix[y_t, y_p] += 1  # Increment count for actual class (row) and predicted class (column)\n",
        "       return matrix\n",
        "    def plot(self):\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(self.matrix, annot=True, cmap='Blues', fmt='d', xticklabels=np.arange(self.n_classes), yticklabels=np.arange(self.n_classes))\n",
        "        plt.xlabel('Predicted labels')\n",
        "        plt.ylabel('True labels')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "class EvaluationMetrics:\n",
        "    def __init__(self, y_true, y_pred):\n",
        "        self.y_true = y_true\n",
        "        self.y_pred = y_pred\n",
        "        self.confusion_matrix = ConfusionMatrix(y_true, y_pred)\n",
        "        self.metrics = self._compute_metrics()\n",
        "\n",
        "    def _compute_metrics(self):\n",
        "        tp = np.diag(self.confusion_matrix.matrix)\n",
        "        tn = cm.sum(axis=0) - tp  # True negatives (correct non-predictions) - sum across rows (predicted class) excluding diagonal\n",
        "        fp = cm.sum(axis=1) - tp  # False positives (incorrect predictions) - sum across columns (true class) excluding diagonal\n",
        "        fn = cm.sum(axis=0) - tn  # False negatives (missed positives) - sum across rows excluding diagonal\n",
        "\n",
        "\n",
        "            # Derive other metrics from basic counts\n",
        "        sensitivity = tp / (tp + fn)  # True Positive Rate (TPR), Recall\n",
        "        specificity = tn / (tn + fp)  # True Negative Rate (TNR)\n",
        "        fpr = fp / (fp + tn)  # False Positive Rate (FPR)\n",
        "        fnr = fn / (tp + fn)  # False Negative Rate (FNR)\n",
        "        precision = tp / (tp + fp)  # Positive Predictive Value (PPV)\n",
        "        recall = tp / (tp + fn)\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "        return {\n",
        "            'Sensitivity': sensitivity,\n",
        "            'Specificity': specificity,\n",
        "            'FPR': fpr,\n",
        "            'FNR': fnr,\n",
        "            'Precision': precision,\n",
        "            'Recall': recall,\n",
        "            'F1 Score': f1_score\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "#Write a main to test all the above functions\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate sample classification data\n",
        "X, y = make_classification(n_samples=100, n_features=10, n_classes=2, random_state=42)\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier object\n",
        "knn_classifier = NearestNeighborClassifierManual()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "\n",
        "# Create a GNB classifier object\n",
        "gnb_classifier = GaussianNaiveBayesClassifierManual()\n",
        "gnb_classifier.fit(X_train, y_train)\n",
        "y_pred_gnb = gnb_classifier.predict(X_test)\n",
        "\n",
        "# Print evaluation metrics for KNN\n",
        "print(\"KNN Classifier Evaluation:\")\n",
        "evaluation_metrics_knn = EvaluationMetrics(y_test, y_pred_knn)\n",
        "print(evaluation_metrics_knn.metrics)\n",
        "\n",
        "# Print evaluation metrics for GNB\n",
        "print(\"GNB Classifier Evaluation:\")\n",
        "evaluation_metrics_gnb = EvaluationMetrics(y_test, y_pred_gnb)\n",
        "print(evaluation_metrics_gnb.metrics)\n",
        "\n",
        "# (Optional) Confusion matrix visualization (requires matplotlib and seaborn)\n",
        "# You can uncomment these lines to plot the confusion matrices\n",
        " import matplotlib.pyplot as plt\n",
        " import seaborn as sns\n",
        "\n",
        " knn_classifier.confusion_matrix.plot()\n",
        " gnb_classifier.confusion_matrix.plot()\n",
        "\n"
      ]
    }
  ]
}